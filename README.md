# ðŸŒŒ Image Sonification and Data Extraction Project

This project delves into the fascinating process of *image sonification* and *data extraction*, encompassing two key assignments. ðŸŽ¯ 

---

## ðŸ“¸ Part 1: Image Data Extraction and Visualization  
The objective of this assignment was to explore *image sonification* by extracting pixel data from a high-resolution galaxy image ðŸŒ . Here's how it was achieved:  

- ðŸ›  *Data Extraction*:  
   - Using Python libraries like *OpenCV* or *PIL*, pixel intensities or RGB values were extracted from the image.  
   - The extracted data was stored in a structured format, such as a *CSV file*.  

- ðŸ“Š *Data Visualization*:  
   - The distribution of pixel intensities was visualized using *matplotlib* to gain insights into the image data.  

This step laid the foundation for understanding the relationship between pixel data and potential sound mappings. ðŸŽµ  

---

## ðŸ”Š Part 2: Sound Mapping from Pixel Data  
Building on the extracted data, this assignment involved mapping pixel values to *sound properties*. ðŸŽ¶  

- ðŸŽ¹ *Sound Parameter Mapping*:  
   - A Python function was designed to convert pixel brightness or RGB values into sound parameters like *pitch, **volume, and **duration*.  
   - Short sound clips were generated using libraries such as *pydub* or *pygame*.  

- ðŸŽ§ *Sound Testing and Refinement*:  
   - The mapping logic was tested on small sections of the image to refine the sound generation process.  

---  

Feel free to explore the code and experiment with yourÂ ownÂ images!Â ðŸš€

